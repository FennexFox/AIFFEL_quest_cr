{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n",
      "['class_0' 'class_1' 'class_2']\n",
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# call and read digits dataset\n",
    "\n",
    "wine = load_wine()\n",
    "\n",
    "print(dir(wine))\n",
    "print(wine.target_names)\n",
    "print(wine.DESCR)\n",
    "\n",
    "# assign data for later use\n",
    "\n",
    "wine_feature = wine.data\n",
    "wine_label = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train 개수:  142 , data_test 개수:  36\n",
      "(142, 13) (142,)\n",
      "(36, 13) (36,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data for model training and model testing\n",
    "\n",
    "data_train, data_test, label_train, label_test = train_test_split(wine_feature, wine_label, test_size = 0.2, random_state=7)\n",
    "                                                     \n",
    "print('data_train 개수: ', len(data_train),', data_test 개수: ', len(data_test))\n",
    "print(data_train.shape, label_train.shape)\n",
    "print(data_test.shape, label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn import svm  \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# import metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Trying Decision Tree model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  2 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=32) \n",
    "decision_tree.fit(data_train, label_train)\n",
    "label_prediction = decision_tree.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(label_test, label_prediction))\n",
    "print(classification_report(label_test, label_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Trying Randome Foreest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trying Random Forest model\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32) \n",
    "random_forest.fit(data_train, label_train)\n",
    "label_prediction = random_forest.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(label_test, label_prediction))\n",
    "print(classification_report(label_test, label_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Trying Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  0  1]\n",
      " [ 1 15  1]\n",
      " [ 0 11  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trying Support Vector Machine\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(data_train, label_train)\n",
    "label_prediction = svm_model.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(label_test, label_prediction))\n",
    "print(classification_report(label_test, label_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Trying Stochastic Gradient Descent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  0  0]\n",
      " [ 2 12  3]\n",
      " [ 4  4  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70         7\n",
      "           1       0.75      0.71      0.73        17\n",
      "           2       0.57      0.33      0.42        12\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.62      0.68      0.62        36\n",
      "weighted avg       0.65      0.64      0.62        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(data_train, label_train)\n",
    "label_prediction = sgd_model.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(label_test, label_prediction))\n",
    "print(classification_report(label_test, label_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Trying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(max_iter=20000) # 최대 반복횟수 증가\n",
    "logistic_model.fit(data_train, label_train)\n",
    "label_prediction = logistic_model.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(label_test, label_prediction))\n",
    "print(classification_report(label_test, label_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델을 평가해 보기\n",
    "와인의 등급을 판별하는 문제의 경우, 각 등급에 따라 정밀도와 재현율의 중요성이 달라지는 점이 특이하다. 높은 등급의 와인을 낮은 등급으로 잘못 판정했을 경우, 낮은 와인 판별의 재현율과 높은 등급 와인 판별의 정밀도가 떨어지지만, 그 판정을 믿고 와인을 구매한 소비자 입장에서는 큰 불만을 제기하지 않을 것이다. 반면, 낮은 등급 와인을 높은 등급 와인으로 잘못 판정했을 경우, 낮은 와인 판별의 정밀도와 높은 등급 와인 판별의 재현율이 떨어지며, 소비자는 큰 불만을 제기할 것이다. 이런 점에서 소비자는 높은 등급 와인 판정에는 재현율이 중요하다고 여길 것이며, 낮은 등급 와인 판정에는 재현율이 덜 중요하다고 여길 것이다. 반대로, 판매자의 입장에서는 높은 등급 와인의 정밀도가 중요하다고 여길 것이며, 낮은 등급 와인 판정에는 정밀도가 덜 중요하다고 여길 것이다. 이를 종합할 경우 모델 전반적인 정확도보다 높은 등급 와인 판정의 정확도가 더 중요하다.\n",
    "\n",
    "해당 평가기준에 따라 5가지 모델을 비교하면 다음과 같다.\n",
    "\n",
    "|모델명|모델 전체의 w.avg of f1-score|class 2의 f1-score|순위|\n",
    "|---|---|---|---|\n",
    "|의사결정나무|0,94|0.91|3|\n",
    "|랜덤포레스트|1.0|1.0|1|\n",
    "|SVM|0.54|0.13|4|\n",
    "|SGD|0.62|0.42|5|\n",
    "|로지스틱|0.97|0.96|2|\n",
    "\n",
    "하위권에 위치한 SVM과 SGD의 경우, 모델 전체의 정확도 순위와 class 2의 정확도 순위가 다른 것을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
